# -*- coding: utf-8 -*-
"""BRESSAN_ComputerScience

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ueH8-8StvLf_jngtgChgeeIzwrVHLfZW

# "Foundations of Computer Science" course (F9101Q001)
## Final Project

**Matteo Bressan - 765957**


---

The current project refers to [this provided guideline](http://gianluca.dellavedova.org/foundationsCS/2019-project)

####0.   **Common part - Libraries, configurations and files import**
"""

import pandas as pd
import numpy as np
from datetime import datetime
from calendar import isleap

from google.colab import drive
drive.mount('/content/drive')

loans_lenders_url = '/content/drive/My Drive/additional-kiva-snapshot/loans_lenders.csv'
loans_lenders_import = pd.read_csv(loans_lenders_url)
loans_lenders_import.dtypes

loans_lenders_import.head(2)

loans_url = '/content/drive/My Drive/additional-kiva-snapshot/loans.csv'
loans_import = pd.read_csv(loans_url)
loans_import.dtypes

loans_import.head(2)

lenders_url = '/content/drive/My Drive/additional-kiva-snapshot/lenders.csv'
lenders_import = pd.read_csv(lenders_url)
lenders_import.dtypes

lenders_import.head(5)

country_stats_url = '/content/drive/My Drive/additional-kiva-snapshot/country_stats.csv'
country_stats_import = pd.read_csv(country_stats_url)
country_stats_import.dtypes

country_stats_import.head(5)

"""## Questions

####1.   **Normalize the loan_lenders table. In the normalized table, each row must have one loan_id and one lender.**

First of all, I cast the _lenders_ variable as an array
"""

loans_lenders_import['lenders'] = loans_lenders_import.lenders.apply(lambda x: x.split(','))
loans_lenders_import.head(2)

"""Then, I can explode _lenders_ variable.

Please note: ".drop_duplicates()" is used to avoid duplicated lenders for load_in, if present in the original _lenders_ array
"""

loans_lenders = loans_lenders_import.explode('lenders').drop_duplicates()
loans_lenders.head(5)

"""####2.   **For each loan, add a column duration corresponding to the number of days between the disburse time and the planned expiration time. If any of those two dates is missing, also the duration must be missing.**

I calculate _duration_ on the _loans_ dataframe, converting needed columns to datetime.

Please note: with _errors="coerce"_ option the system will set to NaN all values that cannot be converted.
"""

loans_import['planned_expiration_time']= pd.to_datetime(loans_import['planned_expiration_time'], format="%Y-%m-%d %H:%M:%S", errors="coerce") 
loans_import['disburse_time']= pd.to_datetime(loans_import['disburse_time'], format="%Y-%m-%d %H:%M:%S", errors="coerce")

loans_import['duration'] = loans_import['planned_expiration_time'] - loans_import['disburse_time']
loans_import.head(5)

"""####3.   **Find the lenders that have funded at least twice.**"""

lender_foundings = loans_lenders.groupby('lenders').size().reset_index(name='foundings')
lender_foundings[lender_foundings['foundings'] > 2]

"""####4.   **For each country, compute how many loans have involved that country as borrowers.**"""

country_loans = loans_import.groupby('country_code').size().reset_index(name='loans')
country_loans.head(10)

"""####5.   **For each country, compute the overall amount of money borrowed.**"""

country_loans_amount = loans_import.groupby('country_code')['loan_amount'].agg('sum').reset_index(name='overall_founds')
country_loans_amount.head(5)

"""####6.   **Like the previous point, but expressed as a percentage of the overall amount lent.**"""

country_loans_amount['overall_founds_perc'] = country_loans_amount.overall_founds / country_loans_amount.overall_founds.sum()

country_loans_amount.head(5)

"""####7.   **Like the three previous points, but split for each year (with respect to disburse time).**"""

loans_import['disburse_year'] = pd.DatetimeIndex(loans_import['disburse_time']).year

country_year_loans = loans_import.groupby(['country_code','disburse_year']).size().reset_index(name='loans')
country_year_loans_amount = loans_import.groupby(['country_code','disburse_year'])['loan_amount'].agg('sum').reset_index(name='overall_founds')
country_year_loans_amount['overall_founds_perc'] = country_year_loans_amount.overall_founds / country_year_loans_amount.overall_founds.sum()

country_year_loans.head(5)

country_year_loans_amount.head(5)

"""####8.   **For each lender, compute the overall amount of money lent. For each loan that has more than one lender, you must assume that all lenders contributed the same amount.**

First of all, I need to assing to each lender/loan, the corresponding loan's details. So, I need to join the 2 dataset. To avoid run out of RAM, I reduce the number of variables selected on _loans_import_
"""

lender_loan_details = pd.merge(
                        loans_lenders,
                        loans_import[['loan_id','loan_amount']],
                        left_on=  ['loan_id'],
                        right_on= ['loan_id'], 
                        how = 'inner')

lender_loan_details.head(5)

"""Then, it's possible to group the dataset to obtain the overall amount of money lent"""

lender_loan_details.groupby('lenders')['loan_amount'].agg('sum').reset_index(name='overall_money_lent')

"""####9.   **For each country, compute the difference between the overall amount of money lent and the overall amount of money borrowed. Since the country of the lender is often unknown, you can assume that the true distribution among the countries is the same as the one computed from the rows where the country is known.**

First of all, I join the _lenders_ and the _loans_lenders_ dataset by lender name, removing lenders without a country code associated
"""

lenders_import_filtered = lenders_import[lenders_import.country_code.notnull()]

lender_loan_country = pd.merge(
                        loans_lenders,
                        lenders_import_filtered[['permanent_name','country_code']],
                        left_on=  ['lenders'],
                        right_on= ['permanent_name'], 
                        how = 'inner')

lender_loan_country['lender_country'] = lender_loan_country['country_code']

lender_loan_country = lender_loan_country[['loan_id', 'lender_country']]

lender_loan_country.head(5)

"""Then, I join obtained dataset with the _loans_ dataset by loan ID"""

lender_loan_country_full = pd.merge(
                        lender_loan_country.drop_duplicates(),
                        loans_import[['loan_id','loan_amount','country_code']],
                        left_on=  ['loan_id'],
                        right_on= ['loan_id'], 
                        how = 'inner')

lender_loan_country_full['borrowed_country'] = lender_loan_country_full['country_code']

lender_loan_country_group = lender_loan_country_full.groupby(['lender_country','borrowed_country'])['loan_amount'].agg('sum').reset_index(name='overall_founds')
lender_loan_country_group.head(5)

"""Finally, I can group the obtained dataset by the 2 country columns to obtain requested information"""

lender_loan_country_group_borrowers = lender_loan_country_group.groupby(['borrowed_country'])['overall_founds'].agg('sum').reset_index(name='amount_borrowed')
lender_loan_country_group_lenders = lender_loan_country_group.groupby(['lender_country'])['overall_founds'].agg('sum').reset_index(name='amount_lent')

lender_loan_country_group_join = pd.merge(
                        lender_loan_country_group_borrowers,
                        lender_loan_country_group_lenders,
                        left_on=  ['borrowed_country'],
                        right_on= ['lender_country'], 
                        how = 'inner')


lender_loan_country_group_join['country'] = lender_loan_country_group_join['borrowed_country']
lender_loan_country_group_join = lender_loan_country_group_join[['country','amount_borrowed','amount_lent']]

lender_loan_country_group_join['lent_borrowed_ratio'] = lender_loan_country_group_join['amount_borrowed']/lender_loan_country_group_join['amount_lent']
lender_loan_country_group_join['lent_borrowed_delta'] = lender_loan_country_group_join['amount_borrowed'] - lender_loan_country_group_join['amount_lent']

lender_loan_country_group_join.head(5)

"""####10.   **Which country has the highest ratio between the difference computed at the previous point and the population?**

To evaluate this ratio, I've to join the previously created dataset with the _country_stats_ one
"""

lender_loan_country_group_stats = pd.merge(
                        lender_loan_country_group_join,
                        country_stats_import,
                        left_on=  ['country'],
                        right_on= ['country_code'], 
                        how = 'inner')

"""Then, I can compute the requested KPI"""

lender_loan_country_group_stats1 = lender_loan_country_group_stats
lender_loan_country_group_stats1['population_ratio'] = lender_loan_country_group_stats1['lent_borrowed_delta']/lender_loan_country_group_stats1['population']
lender_loan_country_group_stats1 = lender_loan_country_group_stats1[['country','lent_borrowed_delta','population_ratio']]
lender_loan_country_group_stats1.head(5)

"""####11.   **Which country has the highest ratio between the difference computed at point 9 and the population that is not below the poverty line?**

To evaluate it, we have to multiply the overall population number and the _population_below_poverty_line_ ratio information
"""

lender_loan_country_group_stats2 = lender_loan_country_group_stats
lender_loan_country_group_stats2['population_weighed'] = lender_loan_country_group_stats2['population_below_poverty_line'] * lender_loan_country_group_stats2['population']
lender_loan_country_group_stats2['population_weighed_ratio'] = lender_loan_country_group_stats2['lent_borrowed_delta']/lender_loan_country_group_stats2['population_weighed']
lender_loan_country_group_stats2 = lender_loan_country_group_stats2[['country','lent_borrowed_delta','population_ratio', 'population_weighed_ratio']]
lender_loan_country_group_stats2.head(5)

"""####12.   **For each year, compute the total amount of loans. Each loan that has planned expiration time and disburse time in different years must have its amount distributed proportionally to the number of days in each year. For example, a loan with disburse time December 1st, 2016, planned expiration time January 30th 2018, and amount 5000USD has an amount of 5000USD * 31 / (31+365+30) = 363.85 for 2016, 5000USD * 365 / (31+365+30) = 4284.04 for 2017, and 5000USD * 30 / (31+365+30) = 352.11 for 2018.**

Let's start defining a function that, given needed information (start date, end date and value) split it by years.
"""

def divide_value_by_period(row):  
  start_date = row['disburse_time'].tz_localize(None)
  end_date = row['planned_expiration_time'].tz_localize(None)
  value = row['loan_amount']

  # calculating the difference in years considewring leap years
  jumps = end_date.year - start_date.year
  if jumps != 0:
    dayss = []
    starting_year = start_date.year
    
    for i in range(jumps):
      next_year = starting_year + 1
      next_year_comp = datetime(next_year, 1, 1)
      
      # get the difference in days
      diff = (next_year_comp - start_date).days
      dayss.append(diff)
      # re-assigning start and end dates
      starting_year = next_year_comp.year
      start_date = next_year_comp
  
    # adding the days between the end date and the first day of the last year
    dayss.append(((end_date - start_date).days) + 1) 
  
    # calculating the portion of value each period gets 
    if sum(dayss) > 0:
      return [(x*value)/sum(dayss) for x in dayss]
    else:
      return value
  else:
    return value

"""Now, we can apply the funciton to the dataset, removing rows where one of the 2 dates are missing.
I also apply a check on overall duration, to remove issues (duration <= 0 days)
"""

time_loans = loans_import[loans_import.disburse_time.notnull() & loans_import.planned_expiration_time.notnull()]
time_loans = time_loans[time_loans.duration > pd.Timedelta(0,'D')]
time_loans['YearSplit'] = time_loans.apply(divide_value_by_period, axis=1)

time_loans.head(5)